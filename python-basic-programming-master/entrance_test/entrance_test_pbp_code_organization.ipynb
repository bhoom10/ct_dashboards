{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Python Entry Test\n",
    "\n",
    "## Part 3 of 4: Code Organization (Indentation, execution flow, import, functions)\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Below are 5 Exercises: python problems you need to solve, in order to pass this test. For each correct answer, you will be assigned points, with a maximum of 100 points in total. If you score 80 points or higher, you have passed the test. You cannot see your score immediately; your test will be graded as part of a batch job, later on.\n",
    "\n",
    "Note the following:\n",
    "1. You are asked to code in **Python3** (version 3), not Python2\n",
    "2. For some answers, you obtain a *skeleton*, to frame your answer. You are asked to complete it\n",
    "3. The answer you are expected to given starts where it says:\n",
    "```python\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "```\n",
    "   Start your answer by *removing these two lines*. Do not put your answer anywhere else than *just here, in this box*\n",
    "4. You may use as many lines for your answer as you see necessary\n",
    "5. In general, however, no more than 5 lines of code are needed\n",
    "6. Ignore all boxes that are completely empty; just focus on `# YOUR CODE HERE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Begin of the Test\n",
    "\n",
    "#### Exercise 1: below is a piece of code that, if you run it, yields an `IndentationError`. You are asked to correct all the indentation of the source code, so that the program runs and produces the correct result: `code=10`. Do not remove, change or add any code; just repair the indentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-3-492cd03a7fd3>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-492cd03a7fd3>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    def square_root(x):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "    import math\n",
    "    \n",
    " def square_root(x):\n",
    "    return math.sqrt(x)\n",
    "\n",
    " def run():\n",
    "      print('code={:d}'. \\\n",
    "            format(int(square_root(100))))\n",
    "    \n",
    "# call run() to run this code ...\n",
    "run()\n",
    "### BEGIN SOLUTION\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "at11",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "sequences",
     "functionals"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_import_indentation (__main__.MyEntryTestClasses)\n",
      "verify fimport math availlable ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_import_indentation (__main__.MyEntryTestClasses)\n",
      "verify fimport math availlable\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-4-67b86646ddd8>\", line 9, in test_import_indentation\n",
      "    okey = hasattr(math, 'pi' )\n",
      "NameError: name 'math' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-4-67b86646ddd8>\", line 11, in test_import_indentation\n",
      "    self.fail(\"test import and use math failed\")\n",
      "AssertionError: test import and use math failed\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.003s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "import unittest\n",
    "\n",
    "class MyEntryTestClasses(unittest.TestCase):\n",
    "\n",
    "    def test_import_indentation(self):\n",
    "        ''' verify fimport math availlable '''\n",
    "        try:\n",
    "            okey = hasattr(math, 'pi' )\n",
    "        except Exception:\n",
    "            self.fail(\"test import and use math failed\")\n",
    "            \n",
    "def run_MyEntryTestClasses():\n",
    "    suite = unittest.TestLoader().loadTestsFromTestCase(MyEntryTestClasses)\n",
    "    unittest.TextTestRunner(verbosity=2).run(suite)\n",
    "\n",
    "run_MyEntryTestClasses()\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "at12",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "sequences",
     "functionals"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_indentation_corrected_ok (__main__.MyEntryTestClasses)\n",
      "verify function square_root() is callable ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_indentation_corrected_ok (__main__.MyEntryTestClasses)\n",
      "verify function square_root() is callable\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-5-2ebe7053843c>\", line 9, in test_indentation_corrected_ok\n",
      "    sqrt = square_root(100)\n",
      "NameError: name 'square_root' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-5-2ebe7053843c>\", line 12, in test_indentation_corrected_ok\n",
      "    self.fail(\"test indentation corrected Ok failed\")\n",
      "AssertionError: test indentation corrected Ok failed\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "import unittest\n",
    "\n",
    "class MyEntryTestClasses(unittest.TestCase):\n",
    "\n",
    "    def test_indentation_corrected_ok(self):\n",
    "        ''' verify function square_root() is callable '''\n",
    "        try:\n",
    "            sqrt = square_root(100)\n",
    "            assert sqrt == 10\n",
    "        except Exception:\n",
    "            self.fail(\"test indentation corrected Ok failed\")\n",
    "            \n",
    "def run_MyEntryTestClasses():\n",
    "    suite = unittest.TestLoader().loadTestsFromTestCase(MyEntryTestClasses)\n",
    "    unittest.TextTestRunner(verbosity=2).run(suite)\n",
    "\n",
    "run_MyEntryTestClasses()\n",
    "### END HIDDEN TESTS   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "at13",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "sequences",
     "functionals"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_correct_source_indentation (__main__.MyEntryTestClasses) ... ERROR\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_correct_source_indentation (__main__.MyEntryTestClasses)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-6-6beeb4031bbf>\", line 24, in test_correct_source_indentation\n",
      "    run()\n",
      "NameError: name 'run' is not defined\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    }
   ],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "import sys\n",
    "import unittest\n",
    "from contextlib import contextmanager\n",
    "from io import StringIO\n",
    "\n",
    "@contextmanager\n",
    "def captured_output():\n",
    "    new_out, new_err = StringIO(), StringIO()\n",
    "    old_out, old_err = sys.stdout, sys.stderr\n",
    "    try:\n",
    "        sys.stdout, sys.stderr = new_out, new_err\n",
    "        yield sys.stdout, sys.stderr\n",
    "    finally:\n",
    "        sys.stdout, sys.stderr = old_out, old_err\n",
    "\n",
    "    \n",
    "class MyEntryTestClasses(unittest.TestCase):\n",
    "\n",
    "    def test_correct_source_indentation(self):\n",
    "        \n",
    "        expected_string = 'code=10'   \n",
    "        with captured_output() as (out, err):\n",
    "            run()\n",
    "\n",
    "        output = out.getvalue().strip()\n",
    "        self.assertEqual(output, expected_string)\n",
    "        \n",
    "def run_MyEntryTestClasses():\n",
    "    suite = unittest.TestLoader().loadTestsFromTestCase(MyEntryTestClasses)\n",
    "    unittest.TextTestRunner(verbosity=2).run(suite)\n",
    "\n",
    "run_MyEntryTestClasses()\n",
    "### END HIDDEN TESTS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Exercise 2: the below code is not printing anything. Why not? Repair it by adding exactly two lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here is your answer!\n"
     ]
    }
   ],
   "source": [
    "def give_me_the_answer(text):\n",
    "    print('{:s}'.format(text))\n",
    "    \n",
    "def prepare_the_answer(immediate):\n",
    "    if immediate == True:\n",
    "        answer = \"here is your answer!\"\n",
    "    else:\n",
    "        answer = \"\"\n",
    "    return answer\n",
    "\n",
    "# add a single line setting a variable ...\n",
    "### BEGIN SOLUTION\n",
    "NOW = True\n",
    "### END SOLUTION\n",
    "\n",
    "text = prepare_the_answer(NOW)\n",
    "\n",
    "# add a single line here to produce the output ...\n",
    "### BEGIN SOLUTION\n",
    "give_me_the_answer(text)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "at21",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "sequences",
     "functionals"
    ]
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "from nose.tools import assert_equal\n",
    "assert_equal(NOW, True)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "at22",
     "locked": true,
     "points": 12,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "sequences",
     "functionals"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_printing_answer (__main__.MyEntryTestClasses) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "import sys\n",
    "import unittest\n",
    "from contextlib import contextmanager\n",
    "from io import StringIO\n",
    "\n",
    "@contextmanager\n",
    "def captured_output():\n",
    "    new_out, new_err = StringIO(), StringIO()\n",
    "    old_out, old_err = sys.stdout, sys.stderr\n",
    "    try:\n",
    "        sys.stdout, sys.stderr = new_out, new_err\n",
    "        yield sys.stdout, sys.stderr\n",
    "    finally:\n",
    "        sys.stdout, sys.stderr = old_out, old_err\n",
    "\n",
    "    \n",
    "class MyEntryTestClasses(unittest.TestCase):\n",
    "\n",
    "    def test_printing_answer(self):\n",
    "        \n",
    "        expected_output = 'here is your answer!'\n",
    "        \n",
    "        with captured_output() as (out, err):\n",
    "            give_me_the_answer(text)\n",
    "    \n",
    "        # This can go inside or outside the `with` block\n",
    "        output = out.getvalue().strip()\n",
    "        self.assertEqual(output, expected_output)\n",
    "        \n",
    "def run_MyEntryTestClasses():\n",
    "    suite = unittest.TestLoader().loadTestsFromTestCase(MyEntryTestClasses)\n",
    "    unittest.TextTestRunner(verbosity=2).run(suite)\n",
    "\n",
    "run_MyEntryTestClasses()\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Exercise 3: in the below code skeleton, insert the necessary `import`'s as specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import math and name it by the alias m\n",
    "# import numpy and name it by the alias np\n",
    "# import nose.tools and name it nt\n",
    "### BEGIN SOLUTION\n",
    "import math as m\n",
    "import numpy as np\n",
    "import nose.tools as nt\n",
    "### END SOLUTION\n",
    "\n",
    "my_sqrt = m.sqrt(m.pi)\n",
    "my_other_sqrt = np.sqrt(np.pi)\n",
    "\n",
    "# check the result to be (almost) equal ...\n",
    "nt.assert_almost_equal(my_sqrt, my_other_sqrt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "at31",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "sequences"
    ]
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "from nose.tools import assert_true\n",
    "import math\n",
    "assert_true( m.pi is math.pi  and  m.sqrt is math.sqrt )\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "at32",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "sequences"
    ]
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "from nose.tools import assert_almost_equal\n",
    "import math\n",
    "assert_almost_equal(my_sqrt, math.sqrt(math.pi))\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "at33",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "sequences"
    ]
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "from nose.tools import assert_almost_equal\n",
    "assert_almost_equal(my_other_sqrt, np.sqrt(np.pi))\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "at34",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "sequences"
    ]
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "# should work without an additional\n",
    "from nose.tools import assert_almost_equal\n",
    "assert_almost_equal(my_sqrt, my_other_sqrt)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Exercise 4: the below code should print: `Every word is now in the correct order`. Initially, however, when you first run it, it prints: `Every sentence is now in the wrong order`. You are asked, by moving around whole lines of code, to rearrange the code such that it produces the desired output. \n",
    "\n",
    "You should:\n",
    "\n",
    " 1.   not add any code\n",
    " 2.   not take out (delete) any code\n",
    " 3.   not split up lines, change, or move around parts of one line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every sentence is now in the wrong order\n",
      "Every word is now in the correct order\n"
     ]
    }
   ],
   "source": [
    "# print the right answer with the code elements given below\n",
    "# \n",
    "# the right answer to this exercise is:\n",
    "#\n",
    "# \"Every word is now in the correct order\" \n",
    "#\n",
    "# If your code prints this, your done.\n",
    "\n",
    "word = 'sentence'\n",
    "\n",
    "yes_or_no = True\n",
    "yes_or_no = False\n",
    "\n",
    "def right_answer(flag):\n",
    "    if flag == True:\n",
    "        return 'the correct order'\n",
    "    else:\n",
    "        return 'the wrong order'\n",
    "\n",
    "ans1 = 'Every {0} is now in '.format(word)\n",
    "ans2 = right_answer(yes_or_no)\n",
    "\n",
    "def do_print(ans1, ans2):\n",
    "    print(ans1+ans2)\n",
    "\n",
    "do_print(ans1,ans2)\n",
    "\n",
    "word = 'word'\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "# print the right answer with the code elements given below\n",
    "# \n",
    "# the right answer to this exercise is:\n",
    "#\n",
    "# \"Every word is now in the correct order\" \n",
    "#\n",
    "# If your code prints this, your done.\n",
    "\n",
    "def do_print(ans1, ans2):\n",
    "    print(ans1+ans2)\n",
    "\n",
    "def right_answer(flag):\n",
    "    if flag == True:\n",
    "        return 'the correct order'\n",
    "    else:\n",
    "        return 'the wrong order'\n",
    "\n",
    "word = 'sentence'\n",
    "word = 'word'\n",
    "\n",
    "yes_or_no = False\n",
    "yes_or_no = True\n",
    "\n",
    "ans1 = 'Every {0} is now in '.format(word) \n",
    "ans2 = right_answer(yes_or_no)\n",
    "\n",
    "do_print(ans1, ans2 )\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "at41",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "sequences",
     "functionals"
    ]
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "from nose.tools import assert_equal\n",
    "assert_equal(yes_or_no, True)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "at42",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "sequences",
     "functionals"
    ]
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "from nose.tools import assert_equal\n",
    "assert_equal(word, 'word')\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "at43",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "sequences",
     "functionals"
    ]
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "from nose.tools import assert_equal\n",
    "assert_equal(ans1, 'Every word is now in ')\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "at44",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "sequences",
     "functionals"
    ]
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "from nose.tools import assert_equal\n",
    "assert_equal(ans2, 'the correct order')\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "at45",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "sequences",
     "functionals"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_execution_flow_revision (__main__.MyEntryTestClasses) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "import sys\n",
    "import unittest\n",
    "from contextlib import contextmanager\n",
    "from io import StringIO\n",
    "\n",
    "@contextmanager\n",
    "def captured_output():\n",
    "    new_out, new_err = StringIO(), StringIO()\n",
    "    old_out, old_err = sys.stdout, sys.stderr\n",
    "    try:\n",
    "        sys.stdout, sys.stderr = new_out, new_err\n",
    "        yield sys.stdout, sys.stderr\n",
    "    finally:\n",
    "        sys.stdout, sys.stderr = old_out, old_err\n",
    "\n",
    "    \n",
    "class MyEntryTestClasses(unittest.TestCase):\n",
    "\n",
    "    def test_execution_flow_revision(self):\n",
    "        \n",
    "        expected_output = 'Every word is now in the correct order'\n",
    "        \n",
    "        with captured_output() as (out, err):\n",
    "            do_print(ans1, ans2)\n",
    "    \n",
    "        # This can go inside or outside the `with` block\n",
    "        output = out.getvalue().strip()\n",
    "        self.assertEqual(output, expected_output)\n",
    "        \n",
    "def run_MyEntryTestClasses():\n",
    "    suite = unittest.TestLoader().loadTestsFromTestCase(MyEntryTestClasses)\n",
    "    unittest.TextTestRunner(verbosity=2).run(suite)\n",
    "\n",
    "run_MyEntryTestClasses()\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Exercise 5: given a list of samples `all_samples`, containing all samples taken from some process. Samples have a number (an *id*) representing their time of sampling: (example: a sample `1630` has been taken at `16:30h`). This list `all_samples` needs to be filtered, as follows:\n",
    "\n",
    "- remove all rejected samples (samples to reject have been specified by their id's in an auxiliary list called `samples_rejected`)\n",
    "- remove all samples taken after some deadline (recall that a sample id reflects the time of sampling)\n",
    " \n",
    "Below is a skeleton, containing a couple of functions you are to complete. Using these functions, you are asked to split `all_samples` in two new lists:\n",
    "\n",
    " 1. list `regular_samples` of all samples that are **neither rejected, nor late**\n",
    " 2. a list `samples_removed` of **all other samples**, i.e. removed from the original list\n",
    " \n",
    " Take 20:00h as the deadline (i.e., remove all samples > 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q5",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regular samples: [155, 230, 455, 710, 830, 900, 1005, 1410, 1530, 1630, 1810]\n",
      "samples removed: [340, 352, 507, 1120, 1121, 1930, 2021, 2043, 2136, 2151, 2201]\n"
     ]
    }
   ],
   "source": [
    "# the list of all samples ...\n",
    "all_samples       = [  155,  230,  340,  352,  455,  507,  710,  830,  900, \n",
    "                      1005, 1120, 1121, 1410, 1530, 1630, 1810, 1930, 2021, \n",
    "                      2043, 2136, 2151, 2201 ]\n",
    "\n",
    "# the list of samples rejected ...\n",
    "samples_rejected  = [  340, 352, 507, 1120,  1121, 1930 ]\n",
    "\n",
    "def sample_rejected(s):\n",
    "    '''return T|F s in list samples_rejected'''\n",
    "    ### BEGIN SOLUTION\n",
    "    return s in samples_rejected\n",
    "    ### END SOLUTION\n",
    "    \n",
    "def late_sample(s, deadline):\n",
    "    '''return T|F s taken after deadline'''\n",
    "    ### BEGIN SOLUTION\n",
    "    return s > deadline\n",
    "    ### END SOLUTION\n",
    "\n",
    "def regular_sample(s, deadline):\n",
    "    '''return T|F s is regular (i.e., not rejected or late)'''\n",
    "    ### BEGIN SOLUTION\n",
    "    return not( sample_rejected(s) or late_sample(s, deadline) )\n",
    "    ### END SOLUTION\n",
    "\n",
    "# create the lists and split ...\n",
    "regular_samples = list()\n",
    "samples_removed = list()\n",
    "\n",
    "# deadline for late samples ...\n",
    "deadline = 2000\n",
    "\n",
    "for sample in all_samples:\n",
    "    ### BEGIN SOLUTION\n",
    "    if not regular_sample(sample, deadline):\n",
    "        samples_removed.append(sample)\n",
    "    else:\n",
    "        regular_samples.append(sample)\n",
    "    ### END SOLUTIONS\n",
    "\n",
    "print('regular samples: {:s}'.format(str(regular_samples)))\n",
    "print('samples removed: {:s}'.format(str(samples_removed)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "at51",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "sequences",
     "functionals"
    ]
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "# test predicate sample_reject() ...\n",
    "from nose.tools import assert_true\n",
    "for sample in all_samples:\n",
    "    if sample in samples_rejected:\n",
    "        assert_true( sample_rejected(sample) == True )\n",
    "    else:\n",
    "        assert_true( sample_rejected(sample) == False )\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "at52",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "sequences",
     "functionals"
    ]
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "# test predicate late_sample() ...\n",
    "from nose.tools import assert_true\n",
    "deadline = 2000\n",
    "for sample in all_samples:\n",
    "    assert_true( late_sample(sample,deadline) == (sample > deadline) )\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "at53",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "sequences",
     "functionals"
    ]
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "# test predicate regulat_sample() ...\n",
    "from nose.tools import assert_true\n",
    "deadline = 2000\n",
    "for sample in all_samples:\n",
    "    reject = sample_rejected(sample)\n",
    "    late   = late_sample(sample, deadline)\n",
    "    assert_true( regular_sample(sample, deadline) == (not(reject or late)) )\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "at54",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "sequences",
     "functionals"
    ]
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "from nose.tools import assert_equal\n",
    "deadline = 2000\n",
    "late = [s for s in all_samples if s > deadline]\n",
    "assert_equal(len(samples_removed), len(late)+len(samples_rejected))\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "at55",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "sequences",
     "functionals"
    ]
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "from nose.tools import assert_equal\n",
    "assert_equal(regular_samples, [155, 230, 455, 710, 830, 900, 1005, 1410, 1530, 1630, 1810])\n",
    "assert_equal(samples_removed, [340, 352, 507, 1120, 1121, 1930, 2021, 2043, 2136, 2151, 2201])\n",
    "## END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# End of the Test"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
